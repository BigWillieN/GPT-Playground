# GPT-Playground
Personal playground with some GPT creation code

1. Microgradient.py: My first introduction to Neural Networks. class Neuron takes input, the weight, and 
parameters as data. Passes forward layers of perceptrons with mathematical expressions. Is followed
by the loss function, which measure the accuracy of our predictions. We manipulate the loss function
so when it is low, the network is behaving like we want it to. We back-propagate the loss to get the
gradient and we iterate gradient descent to lower our loss. Neural networks are the idea behind chatgpt any many other AI models. They take billions of parameters
online to compute their result. Although my function only has 41 parameters >:), the neural network
foundation is there.
